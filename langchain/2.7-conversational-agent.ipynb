{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3",
   "metadata": {},
   "source": [
    "# 2.7 Conversational agent\n",
    "\n",
    "(Modified version of lesson 6 of https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)\n",
    "<br/><br/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pip install python-dotenv langchain langchain-openai chromadb docarray --upgrade --quiet\n",
    "%pip install pydantic==1.10.10 --upgrade --quiet"
   ],
   "id": "529c792e3cfe424f"
  },
  {
   "cell_type": "code",
   "id": "36261434-a96c-49e8-ad41-918d14da089a",
   "metadata": {
    "height": 115,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:01.869445Z",
     "start_time": "2024-04-11T08:07:01.866747Z"
    }
   },
   "source": [
    "#import os\n",
    "#import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "20f44fbb-6708-4fce-bac4-55dc261e3a2d",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:03.824905Z",
     "start_time": "2024-04-11T08:07:03.822487Z"
    }
   },
   "source": [
    "from langchain.tools import tool"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "aa7406eb-334b-43d0-8110-31656a55b2fd",
   "metadata": {
    "height": 676,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:03.830573Z",
     "start_time": "2024-04-11T08:07:03.825858Z"
    }
   },
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:03.833803Z",
     "start_time": "2024-04-11T08:07:03.832176Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install wikipedia",
   "id": "3fd076c0a1084e81",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "3ac0a1e7-567f-4775-a538-351a5ff099e8",
   "metadata": {
    "height": 336,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:03.838365Z",
     "start_time": "2024-04-11T08:07:03.834477Z"
    }
   },
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:03.841108Z",
     "start_time": "2024-04-11T08:07:03.839344Z"
    }
   },
   "source": [
    "tools = [get_current_temperature, search_wikipedia]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "cdf0d789-559b-42df-9d6d-77a0cd8888d6",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:04.470507Z",
     "start_time": "2024-04-11T08:07:03.841784Z"
    }
   },
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "933ce7cb-099c-4f43-a548-b355a5b66511",
   "metadata": {
    "height": 132,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:04.531611Z",
     "start_time": "2024-04-11T08:07:04.471132Z"
    }
   },
   "source": [
    "functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n",
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:05.742468Z",
     "start_time": "2024-04-11T08:07:04.532428Z"
    }
   },
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather is sf?\"})"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "b1dbc697-3e0a-4197-8ddc-2894763b4b85",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:05.750228Z",
     "start_time": "2024-04-11T08:07:05.745738Z"
    }
   },
   "source": [
    "result.tool"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "ab829b59-803f-488f-bcf3-5119c224baa0",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:05.753631Z",
     "start_time": "2024-04-11T08:07:05.751037Z"
    }
   },
   "source": [
    "result.tool_input"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "52b4d483-c498-4932-a373-bc2f4da17c7f",
   "metadata": {
    "height": 115,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:05.756690Z",
     "start_time": "2024-04-11T08:07:05.754350Z"
    }
   },
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "66ac6ea2-0e20-424a-ba33-6f8d627379b5",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:05.759455Z",
     "start_time": "2024-04-11T08:07:05.757539Z"
    }
   },
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "bada1de8-d7c4-4880-98c2-d47cc65f684d",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:06.783596Z",
     "start_time": "2024-04-11T08:07:05.760534Z"
    }
   },
   "source": [
    "result1 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\",\n",
    "    \"agent_scratchpad\": []\n",
    "})"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "8d5f4e61-36a3-4d80-9c49-0b83cedb1592",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:06.787008Z",
     "start_time": "2024-04-11T08:07:06.784527Z"
    }
   },
   "source": [
    "result1.tool"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "11845c11-7d41-455a-8ac0-4b8161acaf83",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.018757Z",
     "start_time": "2024-04-11T08:07:06.787592Z"
    }
   },
   "source": [
    "observation = get_current_temperature(result1.tool_input)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "810184c8-8495-4189-b83e-17220cf65bbe",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.023606Z",
     "start_time": "2024-04-11T08:07:07.019951Z"
    }
   },
   "source": [
    "observation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 11.8°C'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "8c1b223d-ea2a-414c-924c-512c4c9da66a",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.028048Z",
     "start_time": "2024-04-11T08:07:07.025156Z"
    }
   },
   "source": [
    "type(result1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "61853679-75b5-4462-8059-f1214286a9eb",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.031069Z",
     "start_time": "2024-04-11T08:07:07.029286Z"
    }
   },
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_functions"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "72ca4278-165a-4915-8ec6-09e696f29d86",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.035961Z",
     "start_time": "2024-04-11T08:07:07.032217Z"
    }
   },
   "source": [
    "result1.message_log"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 136, 'total_tokens': 161}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'function_call', 'logprobs': None}, id='run-b140563a-d37d-455c-a57e-034b3b88dd91-0')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "27e079a7-d58c-41c0-8762-4e183e72a1d1",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.039407Z",
     "start_time": "2024-04-11T08:07:07.036782Z"
    }
   },
   "source": [
    "format_to_openai_functions([(result1, observation), ])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 136, 'total_tokens': 161}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'function_call', 'logprobs': None}, id='run-b140563a-d37d-455c-a57e-034b3b88dd91-0'),\n",
       " FunctionMessage(content='The current temperature is 11.8°C', name='get_current_temperature')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "09735a9e-452d-472b-a4c0-35c315e9e53f",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.834868Z",
     "start_time": "2024-04-11T08:07:07.040250Z"
    }
   },
   "source": [
    "result2 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\", \n",
    "    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n",
    "})"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "9df61ecc-52fe-4fae-85a2-dbb61d68e2db",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.841302Z",
     "start_time": "2024-04-11T08:07:07.836164Z"
    }
   },
   "source": [
    "result2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 11.8°C.'}, log='The current temperature in San Francisco is 11.8°C.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "d9dd139f-e06a-4148-a025-ae100851c63e",
   "metadata": {
    "height": 285,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.852002Z",
     "start_time": "2024-04-11T08:07:07.842828Z"
    }
   },
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "4f6c1121-70a6-41ae-8c3d-41f7cfc756af",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.859817Z",
     "start_time": "2024-04-11T08:07:07.853114Z"
    }
   },
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | chain"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "4a05df88-4ad9-4c48-a7dd-6b42db91cb33",
   "metadata": {
    "height": 268,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:07.863681Z",
     "start_time": "2024-04-11T08:07:07.860764Z"
    }
   },
   "source": [
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = agent_chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"intermediate_steps\": intermediate_steps\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "d8bf88b6-9992-4041-8344-ef4921bf3cf2",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:09.935604Z",
     "start_time": "2024-04-11T08:07:07.864860Z"
    }
   },
   "source": [
    "run_agent(\"what is the weather is sf?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 11.8°C.'}, log='The current temperature in San Francisco is 11.8°C.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "4c94a493-b480-409a-968a-038c8895709c",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:16.269053Z",
     "start_time": "2024-04-11T08:07:09.942221Z"
    }
   },
   "source": [
    "run_agent(\"what is langchain?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.'}, log='LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "7c8c6fd7-7c8c-487a-81de-1dcff739a2f9",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:16.749536Z",
     "start_time": "2024-04-11T08:07:16.270270Z"
    }
   },
   "source": [
    "run_agent(\"hi!\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Well, hello there! How can I assist you today?'}, log='Well, hello there! How can I assist you today?')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "b270a064-8cf1-44da-a59e-be622f9099b9",
   "metadata": {
    "height": 47,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:16.753604Z",
     "start_time": "2024-04-11T08:07:16.750784Z"
    }
   },
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "87baebf4-2555-4e98-aece-a1c327644817",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:21.280024Z",
     "start_time": "2024-04-11T08:07:16.754805Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"what is langchain?\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mPage: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\n",
      "\n",
      "Page: Prompt engineering\n",
      "Summary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text language model can be a query such as \"what is Fermat's little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison → house, chat → cat, chien →\" (the expected response being dog), an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\n",
      "\n",
      "\u001B[0m\u001B[32;1m\u001B[1;3mLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "c2da813c-47c3-487e-8c43-444c9b4d9821",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:22.083944Z",
     "start_time": "2024-04-11T08:07:21.281491Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mNice to meet you, Bob! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "15ba8a9f-fcb2-44d0-878f-3017f607e955",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:23.314833Z",
     "start_time": "2024-04-11T08:07:22.085558Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"what is my name\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI'm sorry, I don't have access to your personal information. How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name',\n",
       " 'output': \"I'm sorry, I don't have access to your personal information. How can I assist you today?\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "7d1df28a-27da-4f8e-ab03-a37a276db74f",
   "metadata": {
    "height": 115,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:23.319033Z",
     "start_time": "2024-04-11T08:07:23.316317Z"
    }
   },
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "a8598e87-de8a-4710-a90e-2a919adc00e2",
   "metadata": {
    "height": 64,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:23.322245Z",
     "start_time": "2024-04-11T08:07:23.320166Z"
    }
   },
   "source": [
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | prompt | model | OpenAIFunctionsAgentOutputParser()"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "a3865c2c-cb80-4341-bcbe-3b5150749622",
   "metadata": {
    "height": 47,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:23.324844Z",
     "start_time": "2024-04-11T08:07:23.323101Z"
    }
   },
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "40b036fc-446f-4075-9a92-9a4bac6ecb2b",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:23.327859Z",
     "start_time": "2024-04-11T08:07:23.325709Z"
    }
   },
   "source": [
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "37f70acf-57ff-4ab9-a942-f0ad6e680c40",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:24.100823Z",
     "start_time": "2024-04-11T08:07:23.328723Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mNice to meet you, Bob! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?')],\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "a1554b0c-8c72-4d8d-bbed-20afd94828c5",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:24.612753Z",
     "start_time": "2024-04-11T08:07:24.102402Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"whats my name\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mYour name is Bob.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats my name',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob.')],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "40887f61-6746-4e51-852d-5ff0457384b7",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:07:27.427091Z",
     "start_time": "2024-04-11T08:07:24.614222Z"
    }
   },
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mThe current temperature is 11.8°C\u001B[0m\u001B[32;1m\u001B[1;3mThe current temperature in San Francisco is 11.8°C.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob.'),\n",
       "  HumanMessage(content='whats the weather in sf?'),\n",
       "  AIMessage(content='The current temperature in San Francisco is 11.8°C.')],\n",
       " 'output': 'The current temperature in San Francisco is 11.8°C.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
